<!DOCTYPE html>
<html lang="en">
<head hexo-theme='https://github.com/volantis-x/hexo-theme-volantis/tree/4.1.1'>
  <meta charset="utf-8">
  <!-- SEO相关 -->
  
    
  
  <!-- 渲染优化 -->
  <meta http-equiv='x-dns-prefetch-control' content='on' />
  <link rel='dns-prefetch' href='https://cdn.jsdelivr.net'>
  <link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <!-- 页面元数据 -->
  
  <title>CVPR 2020 | Using SpixelFCN to Generate the Distinctive Superpixels - Weikun Han&#39;s Website</title>
  

  
    <meta name="description" content="Paper Link: https://arxiv.org/abs/2003.12929，Code Liink: https://github.com/fuy34/superpixel_fcn">
  

  <!-- feed -->
  

  <!-- import meta -->
  

  <!-- link -->
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14/css/all.min.css">

  
  

  

  

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.css">
  

  

  <!-- import link -->
  

  
  
    
<link rel="stylesheet" href="/css/style.css">

  

  <script id="loadcss"></script>

</head>

<body>
  

<header id="l_header" class="l_header auto shadow blur floatable " style='opacity: 0' >
  <div class='container'>
  <div id='wrapper'>
    <div class='nav-sub'>
      <p class="title"></p>
      <ul class='switcher nav-list-h m-phone' id="pjax-header-nav-list">
        <li><a id="s-comment" class="fas fa-comments fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
          <li><a id="s-toc" class="s-toc fas fa-list fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
      </ul>
    </div>
		<div class="nav-main">
      
        
        <a class="title flat-box" target="_self" href='/'>
          
            <img no-lazy class='logo' src='https://cdn.jsdelivr.net/gh/weikunhan/cdn-documents@latest/images/new_weikun_han_web_1.png'/>
          
          
          
        </a>
      

			<div class='menu navigation'>
				<ul class='nav-list-h m-pc'>
          
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/
                  
                  
                  
                    id="home"
                  >
                  <i class='fas fa-home fa-fw'></i>Home
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/projects
                  
                  
                  
                    id="projects"
                  >
                  <i class='fas fa-robot fa-fw'></i>Projects
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/publications
                  
                  
                  
                    id="publications"
                  >
                  <i class='fas fa-file-alt fa-fw'></i>Publications
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/courses
                  
                  
                  
                    id="courses"
                  >
                  <i class='fas fa-graduation-cap fa-fw'></i>Courses
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/awards
                  
                  
                  
                    id="awards"
                  >
                  <i class='fas fa-trophy fa-fw'></i>Awards
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/blogs
                  
                  
                  
                    id="blogs"
                  >
                  <i class='fas fa-book fa-fw'></i>Blogs
                </a>
                
              </li>
            
          
          
				</ul>
			</div>

      <div class="m_search">
        <form name="searchform" class="form u-search-form">
          <i class="icon fas fa-search fa-fw"></i>
          <input type="text" class="input u-search-input" placeholder="Search..." />
        </form>
      </div>

			<ul class='switcher nav-list-h m-phone'>
				
					<li><a class="s-search fas fa-search fa-fw" target="_self" href='javascript:void(0)'></a></li>
				
				<li>
          <a class="s-menu fas fa-bars fa-fw" target="_self" href='javascript:void(0)'></a>
          <ul class="menu-phone list-v navigation white-box">
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/
                  
                  
                  
                    id="home"
                  >
                  <i class='fas fa-home fa-fw'></i>Home
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/projects
                  
                  
                  
                    id="projects"
                  >
                  <i class='fas fa-robot fa-fw'></i>Projects
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/publications
                  
                  
                  
                    id="publications"
                  >
                  <i class='fas fa-file-alt fa-fw'></i>Publications
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/courses
                  
                  
                  
                    id="courses"
                  >
                  <i class='fas fa-graduation-cap fa-fw'></i>Courses
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/awards
                  
                  
                  
                    id="awards"
                  >
                  <i class='fas fa-trophy fa-fw'></i>Awards
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/blogs
                  
                  
                  
                    id="blogs"
                  >
                  <i class='fas fa-book fa-fw'></i>Blogs
                </a>
                
              </li>
            
          
            
          </ul>
        </li>
			</ul>
		</div>
	</div>
  </div>
</header>

  <div id="l_body">
    <div id="l_cover">
  
    
        <div id="half" class='cover-wrapper page focus' style="display: ;">
          
            <div id='cover-backstretch'></div>
          
          <div class='cover-body'>
  <div class='top'>
    
    
      <p class="title">Weikun Han</p>
    
    
      <p class="subtitle">「Computer Vision Scientist」</p>
    
  </div>
  <div class='bottom'>
    <div class='menu navigation'>
      <div class='list-h'>
        
          
            <a href="/"
              
              
              id="home">
              <i class='fas fa-home fa-fw'></i><p>Home</p>
            </a>
          
            <a href="/projects"
              
              
              id="projects">
              <i class='fas fa-robot fa-fw'></i><p>Projects</p>
            </a>
          
            <a href="/publications"
              
              
              id="publications">
              <i class='fas fa-file-alt fa-fw'></i><p>Publications</p>
            </a>
          
            <a href="/courses"
              
              
              id="courses">
              <i class='fas fa-graduation-cap fa-fw'></i><p>Courses</p>
            </a>
          
            <a href="/awards"
              
              
              id="awards">
              <i class='fas fa-trophy fa-fw'></i><p>Awards</p>
            </a>
          
            <a href="/blogs"
              
              
              id="blogs">
              <i class='fas fa-blog fa-fw'></i><p>Blogs</p>
            </a>
          
        
      </div>
    </div>
  </div>
</div>

          <div id="scroll-down" style="display: none;"><i class="fa fa-chevron-down scroll-down-effects"></i></div>
        </div>
    
  
  </div>

    <div id='safearea'>
      <div class='body-wrapper' id="pjax-container">
        

<div class='l_main'>
  <article class="article post white-box reveal md shadow article-type-page" id="page" itemscope itemprop="blogPost">
  


  
  <div class="article-meta" id="top">
    
    
    
      <h1 class="title">
        CVPR 2020 | Using SpixelFCN to Generate the Distinctive Superpixels
      </h1>
      <div class='new-meta-box'>
        
      </div>
    
  </div>


  
  <div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_1.png" class="lazyload" data-srcset="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_1.png" srcset="data:image/png;base64,666" alt="Paper Link: https://arxiv.org/abs/2003.12929，Code Liink: https://github.com/fuy34/superpixel_fcn" style="width:600px;"/></div><span class="image-caption">Paper Link: https://arxiv.org/abs/2003.12929，Code Liink: https://github.com/fuy34/superpixel_fcn</span></div>

<a id="more"></a> 

<h2 id="1-Overview-综述"><a href="#1-Overview-综述" class="headerlink" title="1 Overview 综述"></a>1 Overview 综述</h2><p>In computer vision, superpixels help to reduce the number of image primitives for subsequent processing. It converts the pixel-level image to the district-level image, which can be treated as the abstraction of original image information. There are many methods to generate superpixels but only have few attempts to generate it using deep neural networks. Recent paper <em>Superpixel Segmentation with Fully Convolutional Networks</em>, the researchers from The Pennsylvania State University proposed using a fully convolutional network to generate superpixels. The paper was published on CVPR2020, and superpixels would become much more popular with this state-of-art method. </p>
<p>在计算机视觉中，超像素有助于减少用于后续处理的图像基元的数量。 它将像素级别的图像转换为区域级别的图像，可以将其视为原始图像信息的抽象。 生成超像素的方法有很多，但是只有很少的尝试使深度神经网络生成超像素。最近一篇论文《Superpixel Segmentation with Fully Convolutional Networks》，宾大州立的研究人员提出了使用了全卷积网络来生成超像素的方式，论文发表在CVPR2020中。这种全新的超像素生成方式，给其应用带来更广阔的空间。</p>
<p>In the paper, the author has pointed out the challenges to use a fully convolutional network to generate superpixels: “The standard convolution operation is defined on regular grids and becomes inefficient when applied to superpixels.” Therefore, the author used a novel method that accelerates the superpixels generation. </p>
<p>作者在文中指出，使用全卷积生成超像素的挑战在于：“标准卷积运算是在规则网格上定义的，当应用于超像素时其效率会变的很低”。所以本文作者运用了一种更高效的方式，可以使用全卷积网络来快速生成超像素。</p>
<h3 id="1-1-Summary-概要"><a href="#1-1-Summary-概要" class="headerlink" title="1.1 Summary  概要"></a>1.1 Summary  概要</h3><p>In this paper:</p>
<ul>
<li>The author first proposed a method to generate superpixels with a fully convolutional network. According to experimental results, their method is comparable to state-of-the-art superpixel segmentation performance. At the same time, the superpixels generation speed is 50fps.</li>
<li>The author second developed an architecture for dense prediction tasks based on predicted superpixels, which can boost the performance to generate high-resolution outputs. The architecture is combined with a fully convolutional network (used for generated superpixels) to into popular network architecture for stereo matching. In this way, it helps improve disparity estimation accuracy. </li>
</ul>
<p>在这篇论文：</p>
<ul>
<li>作者首先提出了一种用全卷积网络生成超像素的方式。通过结果来看，本方法可以和当今最流行的方法媲美，同时生成超像素的速度可以达到50fps。</li>
<li>其次，作者提出可以将生成的超像素用于后续的密度预测任务，并且有助于得到更好的结果。其思路是，将用于生成超像素的全卷积网络与主流的立体匹配网络相结合，帮助立体匹配网络产生更准确的差距。</li>
</ul>
<h3 id="1-2-Advantages-优势"><a href="#1-2-Advantages-优势" class="headerlink" title="1.2 Advantages 优势"></a>1.2 Advantages 优势</h3><p>In my opinion, there are two points I can learn from it: </p>
<ul>
<li>First, using a fully convolutional network to fast generate superpixels by solving primary inefficient issues. In the future, I can try to use different deep neural networks to generate superpixels. For example, diverse architectures or operators. In this paper, the fully convolutional network is a simple encoder-decoder architecture. I am surprised that why so many researchers could not think of such a simple idea. Most of the time, make complex things more complect may not be a good choice. I should consider the fundamental motivations behind things. For example, in this paper, the author pointed out: “Superpixel is inherently an over-segmentation method. As one of the main purposes of our superpixel method is to perform the detail-preserved downsampling/upsampling to assist the downstream network, it is more important to capture spatial coherence in the local region.” Based on this motivation, the author first inspired an initialization strategy from traditional superpixel algorithms. Then they used a fixed regular grid to find out the local region information rather than compute all pixel-superpixel paris. Finally, using the advantages of a fully convolutional network, superpixel assigned as the highest probability of region pixels. In the end, based on this design idea, it successfully solves inefficient when using deep neural networks to generate superpixels. </li>
<li>Second, the fully convolutional network used to generate superpixels can be more easily combined with many deep neural networks to improve the the overall performance in different computer vision tasks. For example, the author only tried to use superpixels in the dense prediction tasks, which let superpixels assist improve stereo matching performance. Therefore, could this idea be applied to different computer vision tasks to improve related deep neural network performance?</li>
</ul>
<p>个人认为，本文有两个地方可以借鉴：</p>
<ul>
<li>第一，通过解决主要的低效率问题，使全卷积网络可以快速生成超像素。未来可以尝试用更多不同的深度神经网络去生成超像素。比如，不同的结构或者不同的算子。在本文中的全卷积网络是一个编码器-解码器架构。我很好奇，这么通用并且简答的架构，为什么很多研究人员想不到？很多时候，将复杂的结构变的更复杂，可能不如先想明白事情的本质。比如说，作者的在文中指出超像素的本质是：“一种过度分割的方法。其目的是：“为了保留下采样/上采的细节，这样可以辅助下游网络去更好的捕获在某些区域的空间连贯性。”基于这样的目的，作者首先借鉴初始化步骤在传统的超像素生成算法中。其次，利用局部而非全局信息。最后，结合全卷积网络的优势找出局部信息中最有可能点作为超像素的点。这样的设计理念，成功的解决的了用深度神经网络生成超像素的低效问题。</li>
<li>第二， 用于生成超像素的全卷积网络，可以更容易的和很多深度神经网络结合，去提升深度神经网络在不同计算机视觉任务中的性能。例如，作者在文本中只在密度预测任务中，尝试用超像素去辅助主流的立体匹配网络提升其性能。所以，是否可以将这样的想法运用到不同计算机视觉任务中，去提升相应的深度神经网络的性能？</li>
</ul>
<h3 id="1-3-Disadvantages-劣势"><a href="#1-3-Disadvantages-劣势" class="headerlink" title="1.3 Disadvantages 劣势"></a>1.3 Disadvantages 劣势</h3><p>In my opinion, two points need to pay attention: </p>
<ul>
<li>First, by using a fully convolutional network to generate superpixels, the author only proposed to take advantage of 3 x 3 regular grid (total 9 grid cells included). In other words, such local information only produces the fixed number of superpixels. If there are some cases or data, it is hard to get more superpixels and to control the number of the generated superpixel. </li>
<li>Second, when the fully convolutional network used to generate superpixels combined with deep neural networks, it could reduce the output efficiency even though it may make results better. In this paper, the author stated that the superpixels generation speed is 50fps. Tt possible that the overall inference speed is about 50fps or even lower after combining all together. Therefore, the idea may be hard to apply to many applications if there is no better way to solve these problems.</li>
</ul>
<p>个人认为，本文有几个地方需要注意：</p>
<ul>
<li>第一，在作者提出利用全卷积网络生成超像素的方式中，所用的局部信息只有一个3 x 3 区域（也就是9个网格包域）。也就是说，这样局部信息只能生成固定的超像素。如果遇到特定的情况或者特定的数据，很难去生成更多的超像素，同时也很难去控制生成指定数量的超像素。</li>
<li>第二， 将生成超像素的全卷积网络和主流深度神经网络结合，在提升性能的同时，可能会降低其输出的效率。本文中，作者指出生成超像素的速度可以达到50fps。也就说，如果将全卷积网络生成超像素和主流深度神经网络结合，那么其输出结果的效率大概率会被锁定在50fps左右或者更低。因此，如果找不到一种办法可以加速全卷积网络生成超像素，那么可能很难应用到实际中。</li>
</ul>
<h3 id="1-4-Future-后续"><a href="#1-4-Future-后续" class="headerlink" title="1.4 Future 后续"></a>1.4 Future 后续</h3><p>The author will try a similar idea: let the fully convolutional network used to generate superpixels combined with other deep neural networks. It may help with many computer vision subtasks: target segmentation and optical flow estimation tasks. Also, the author will explore more applications that can introduce superpixels.</p>
<p>作者在提出，会将生成超像素的全卷积网络和不同主流深度神经网络结合， 去尝试处理不同的计算机视觉子任务：目标分割和光流估计任务。并且，作者会探索不同的方式去让超像素得到更广的应用。</p>
<p>In my opinion, the first point raised by the author is the same as what I thought before (1.2 Advantages, second point). Also, I believe that when I find different superpixels application scenarios, I can try to use different deep neural networks to generate superpixels. For example, For example, diverse architectures or operators. (1.2 Advantages, first point).</p>
<p>个人认为，作者提出的第一点和我在之前想的（1.2 优势，第二点）一样。除此以外，我觉得当找到不同的超像素应用场景的时候，可以尝试用更多不同的深度神经网络去生成超像素。比如，不同的结构或者不同的算子（1.2 优势，第一点）。</p>
<h2 id="2-Highlight-Details-重点细节"><a href="#2-Highlight-Details-重点细节" class="headerlink" title="2 Highlight Details 重点细节"></a>2 Highlight Details 重点细节</h2><h3 id="2-1-SpixelFCN"><a href="#2-1-SpixelFCN" class="headerlink" title="2.1 SpixelFCN"></a>2.1 SpixelFCN</h3><p>The first highlight of this paper is to propose a fully convolutional network to generate superpixels, SpixelFCN. Different from the traditional way of generating superpixels, the fully convolutional network only uses the local information to generate superpixels. The purpose of this is to reduce unnecessary computation. As shown in the figure below, there are many pixels in the green box and only collect the information in the 3 x 3 red boxes area. Finally, by learning a soft association map, the pixels with the highest probability in the 9 grid cells as superpixels. </p>
<p>本篇论文的第一个亮点是提出了一个全卷积网络生成超像素SpixelFCN。与传统的超像素的生成方式不同，利用全卷积网络生成超像素仅仅关注局部信息。这样做的目的是为了减少不必要的计算。如下图所示，绿框中有很多像素点只收索附近3 x 3红框区域内的信息。最终在9个网格包域中，通过学习到到的一个软关联图，将域中最高概率的像素点设置为超像素点。</p>
<div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_2.png" class="lazyload" data-srcset="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_2.png" srcset="data:image/png;base64,666"/></div></div>

<p>Here, the soft association map can be learned as a fully convolutional network with a simple encoder-decoder architecture. As shown in the figure below, a schematic diagram and please refer to the supplementary materials of the paper for information.</p>
<p>这里的软关联图可以通过一个拥有编码器-解码器架构的全卷积网络学习获得。如下图所示，一个简答的示意图，具体的结构参考原论文的补充材料。</p>
<div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_3.png" class="lazyload" data-srcset="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_3.png" srcset="data:image/png;base64,666"/></div></div>

<p>The author also compared with “Superpixel Sampling Networks” (SSN) in ECCV2018. As shown in the figure below, although they both introduced the fully convolutional network into the design, the author in this paper pointed out their architecture has fundamentally different than SSN. The former just uses the fully convolutional network as a tool, and finally uses K-Means to obtain global information to generate superpixels. The method in this paper generates superpixels with only a simple fully convolutional network without other complicated computations.</p>
<p>作者同时还比较了在ECCV2018中的”Superpixel Sampling Networks”（SSN）。如下图所示，虽然都是引入全卷积网络的想法，但是作者提出的结构和SSN有本质的不用。前者只是把全卷积网络用做一个工具，最后还是要通过K-Means来获取全局信息生成超像素。而后者，仅仅用一个简单的全卷积网络就可以搞定了，不需要其他复杂的计算。</p>
<div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_4.png" class="lazyload" data-srcset="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_4.png" srcset="data:image/png;base64,666"/></div></div>

<p>In the paper, a generated superpixel is composed of two vectors. One represents the superpixel attributes, and the other represents the position of the superpixel. As in the following formula:</p>
<p>论文中，生成的超像素有两个向量组成，一个是代表超像素额属性，另一个代表超像素的位置。如下面公式：</p>
<div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_5.png" class="lazyload" data-srcset="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_5.png" srcset="data:image/png;base64,666"/></div></div>

<p>The pixels can be reconstructed through the above two vectors. As is the following formula:</p>
<p>通过这向量可以重建像素点，如如下面公式：</p>
<div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_6.png" class="lazyload" data-srcset="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_6.png" srcset="data:image/png;base64,666"/></div></div>

<p>Finally, the original pixels and reconstructed pixels can be written as a loss function. As in the following formula, the first term represents similarity, and the second term represents compactness of space:</p>
<p>最后可以将原始像素点和重建像素点，写成一个损失函数。如下面公式，第一项代表相似性，第二项代表空间的紧凑性：</p>
<div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_7.png" class="lazyload" data-srcset="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_7.png" srcset="data:image/png;base64,666"/></div></div>

<p>In addition, the author also tried to use the CIELAB color vector and L2 norm to write a new loss function. At the same time, the author pointed out that this is very similar to Simple Linear Iterative Clustering (SLIC). As is the following formula:</p>
<p>除此以外，作者还尝试用CIELAB色彩向量和L2模去计算。同时，作者指出这么做和Simple Linear Iterative Clustering（SLIC）就非常相似了。如下面公式:</p>
<div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_8.png" class="lazyload" data-srcset="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_8.png" srcset="data:image/png;base64,666"/></div></div>

<p>Keep simplifying the above loss function, which can be done with the one-hot encoding vector of semantic labels. As is the following formula:</p>
<p>继续优化上面的损失函数，可以用一键编码向量来做。如下面公式:</p>
<div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_9.png" class="lazyload" data-srcset="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_9.png" srcset="data:image/png;base64,666"/></div></div>

<p>The author did not stop at this point but tried to continue to optimize the network structure. Since the full convolutional network couldn’t learn the affinity of pixels in the image, the author introduced the Spatial Propagation (SP) proposed by “Learning Affinity via Spatial Propagation Networks” in NIPS2017. Because of building affinity matrix to propagate information in the full convolutional network, the author called Convolutional Spatial Propagation (CSP). As is the following formula:</p>
<p>作者并没有点到为止，而是尝试继续优化网络结构。由于普通的全卷积网络不具备学习图像中像素的相连性，作者这时候引入在NIPS2017中的“Learning Affinity via Spatial Propagation Networks”。其中的Spatial Propagation（SP）可以使全卷积网络可以学习图片像素点之间的相连性。作者这里叫做Convolutional Spatial Propagation（CSP）。如下面公式：</p>
<div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_10.png" class="lazyload" data-srcset="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_10.png" srcset="data:image/png;base64,666"/></div></div>

<p>A slight adjustment is needed above the equation. It should only compare the information of the nearby 3 x 3 red boxes as mentioned earlier. As is the following formula:</p>
<p>这里需要稍作调整，应为之前提到只对比附近3 x 3红框区域信息。所以，如下面公式：</p>
<div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_11.png" class="lazyload" data-srcset="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_11.png" srcset="data:image/png;base64,666"/></div></div>

<h3 id="2-2-SpixelFCN-PSMNet"><a href="#2-2-SpixelFCN-PSMNet" class="headerlink" title="2.2 SpixelFCN + PSMNet"></a>2.2 SpixelFCN + PSMNet</h3><p>The second highlight of this paper is to use the generated superpixels for subsequent density prediction tasks, which can help get better results. Especially, the paper mainly focuses on the stereo matching. In the stereo matching network, there are four channels: height, width, disparity, and feature. To aggregate that information, 3D convolution is required. And, the overall computation consumes large amounts of memory because of the extra “disparity” dimension. In order to generate high-definition results, the general solution is to do a regression analysis of disparity. However, such processing will result in blurring of the object boundary and loss of many details.</p>
<p>本篇论文第二个亮点就是将生成的超像素用于后续的密度预测任务，并且有助于得到更好的结果。作者在论文中选择的是具体应用场景是立体匹配。在立体匹配网络中，有四个通道：高，宽，视差，和特征。由于这样的特性，处理这样的信息需要3D卷积来帮忙。在其中，计算视差消耗了大量的的存储空间，导致无法生成高清的结果。为了解决这样的问题，通用额解决思路是做一个视差的回归分析。但是，这样的处理会导致目标边界的模糊和细节的丢失。</p>
<p>The author proposed to use superpixels as intermediate information to ensure that the regression analysis of disparity will not lose too much information. Therefore, the author used the “Pyramid Stereo Matching Network” (PSMNet) in CVPR2018 as the primary architecture and combined it with SpixelFCN. The author called it SpixelFCN + PSMNet. As shown below.</p>
<p>所以，作者提出了用超像素作为一个中间信息，去保证视差的回归分析不会导致目标边界的模糊和细节的丢失。作者用了CVPR2018中的“Pyramid Stereo Matching Network”（PSMNet）作为主架构，将生成超像素的全卷积网络与之结合。这个网络就是SpixelFCN + PSMNet。如下图所示。</p>
<div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_12.png" class="lazyload" data-srcset="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_12.png" srcset="data:image/png;base64,666"/></div></div>

<p>The overall architecture is not changed too much. It add a downsampling/upsampling scheme based on the predicted superpixels and to integrate it into existing PSMNet. Therefore, the final loss function combines the sum of the losses of the first two networks. As is the following formula:</p>
<p>整个的架构其实没有太大的改动，就是将上采样网络和下采样网络分开加入到PSMNet中。所以，最后的损失函数结合前两个网络的损失和。如下面公式：</p>
<div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_13.png" class="lazyload" data-srcset="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_13.png" srcset="data:image/png;base64,666"/></div></div>

<h2 id="3-Experimental-results-实验结果"><a href="#3-Experimental-results-实验结果" class="headerlink" title="3 Experimental results 实验结果"></a>3 Experimental results 实验结果</h2><h3 id="3-1-SpixelFCN"><a href="#3-1-SpixelFCN" class="headerlink" title="3.1 SpixelFCN"></a>3.1 SpixelFCN</h3><p>As shown in the figure below, the experiment results for superpixel generated by different algorithms on the BSDS500 dataset. The author provided three evaluation metrics. SpixelFCN and other methods are similar.</p>
<p>如下图，根据不同的算法生成的超像素实验结果在BSDS500数据集上。作者提供了三个测试的标准，SpixelFCN和其他方法对比都差不多。</p>
<div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_14.png" class="lazyload" data-srcset="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_14.png" srcset="data:image/png;base64,666"/></div></div>

<p>As shown in the figure below, the experiment results for superpixel generated by different algorithms on the NYUv2 dataset. The author provided three evaluation metrics. SpixelFCN gets slightly better in the second item.</p>
<p>如下图，根据不同的算法生成的超像素实验结果在NYUv2数据集上。还是之前三个测试的标准，SpixelFCN第二项上有小幅的提升。</p>
<div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_15.png" class="lazyload" data-srcset="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_15.png" srcset="data:image/png;base64,666"/></div></div>

<p>As shown in the figure below, compared to the previous two types of fully convolutional networks, using SpixelFCN to generate superpixels is very fast. The inefficient issue is the primary problem that this paper wants to solve.</p>
<p>如下图，相比之前两种以全卷积网络的来说，SpixelFCN生成超像素的速度非常快，表现很突出。这也是本论文主要想解决的问题。</p>
<div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_16.png" class="lazyload" data-srcset="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_16.png" srcset="data:image/png;base64,666"/></div></div>

<p>As shown in the figure below, by using SpixelFCN to generate superpixels, it indicates that the object boundary becomes cleared and help preserve many details </p>
<p>如下图，超像素在实际图片中的结果，结果显示可以很好的处理目标边界的模糊和细节的丢失的问题。</p>
<div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_17.png" class="lazyload" data-srcset="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_17.png" srcset="data:image/png;base64,666"/></div></div>

<h3 id="3-2-SpixelFCN-PSMNet"><a href="#3-2-SpixelFCN-PSMNet" class="headerlink" title="3.2 SpixelFCN + PSMNet"></a>3.2 SpixelFCN + PSMNet</h3><p>As shown in the table below, the author listed the performance of SpixelFCN + PSMNet on SceneFlow and HR-VS dataset. SpixelFCN + PSMNet can provide fewer errors.</p>
<p>如下表，作者列出SpixelFCN + PSMNet在SceneFlow和HR-VS的数据集上的表现。SpixelFCN + PSMNet可以提供更少的误差。</p>
<div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_18.png" class="lazyload" data-srcset="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_18.png" srcset="data:image/png;base64,666"/></div></div>

<p>As shown in the table below, the author listed the performance of SpixelFCN + PSMNet on Middlebury-v3 benchmark. SpixelFCN + PSMNet can provide a better result.</p>
<p>如下表，作者列出SpixelFCN + PSMNet在Middlebury-v3 benchmark上的表现。同样，SpixelFCN + PSMNet有更出色的表现。</p>
<div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_19.png" class="lazyload" data-srcset="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_19.png" srcset="data:image/png;base64,666"/></div></div>

<p>As shown in the figure below, it shows the results of SpixelFCN + PSMNet. The results show that many tiny details can be well captured.</p>
<p>如下图，最后看看具体超像经过SpixelFCN + PSMNet的结果，结果显示可以很好的捕捉到具体的细节。</p>
<div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_20.png" class="lazyload" data-srcset="/images/papers_reading/using_spixelfcn_to_generate_the_distinctive_superpixels/image_20.png" srcset="data:image/png;base64,666"/></div></div>

<h2 id="4-Note-最后寄语"><a href="#4-Note-最后寄语" class="headerlink" title="4 Note 最后寄语"></a>4 Note 最后寄语</h2><p>Welcome to communicate more with my friends who also like computer vision.</p>
<p>希望和喜欢计算机视觉的朋友多多交流。</p>
<h2 id="5-Reference-引用"><a href="#5-Reference-引用" class="headerlink" title="5 Reference 引用"></a>5 Reference 引用</h2><details ><summary> View All 查看全部 </summary>
              <div class='content'>
              <ul><li>Fengting Yang, Qian Sun, Hailin Jin, Zihan Zhou, Superpixel segmentation with fully convolutional networks, CVPR, 2020</li></ul>
              </div>
            </details>


  
  
  
    


  <div class='article-meta' id="bottom">
    <div class='new-meta-box'>
      
    </div>
  </div>


  
  

  
</article>





</div>
<aside class='l_side'>
  
  
    
    



  <section class="widget toc-wrapper shadow blur floatable desktop mobile" id="toc-div" >
    
  <header>
    
      <i class="fas fa-list fa-fw" aria-hidden="true"></i><span class='name'>Contents</span>
    
  </header>


    <div class='content'>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Overview-%E7%BB%BC%E8%BF%B0"><span class="toc-text">1 Overview 综述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-Summary-%E6%A6%82%E8%A6%81"><span class="toc-text">1.1 Summary  概要</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-Advantages-%E4%BC%98%E5%8A%BF"><span class="toc-text">1.2 Advantages 优势</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-Disadvantages-%E5%8A%A3%E5%8A%BF"><span class="toc-text">1.3 Disadvantages 劣势</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-Future-%E5%90%8E%E7%BB%AD"><span class="toc-text">1.4 Future 后续</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Highlight-Details-%E9%87%8D%E7%82%B9%E7%BB%86%E8%8A%82"><span class="toc-text">2 Highlight Details 重点细节</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-SpixelFCN"><span class="toc-text">2.1 SpixelFCN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-SpixelFCN-PSMNet"><span class="toc-text">2.2 SpixelFCN + PSMNet</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Experimental-results-%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="toc-text">3 Experimental results 实验结果</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-SpixelFCN"><span class="toc-text">3.1 SpixelFCN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-SpixelFCN-PSMNet"><span class="toc-text">3.2 SpixelFCN + PSMNet</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Note-%E6%9C%80%E5%90%8E%E5%AF%84%E8%AF%AD"><span class="toc-text">4 Note 最后寄语</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Reference-%E5%BC%95%E7%94%A8"><span class="toc-text">5 Reference 引用</span></a></li></ol>
    </div>
  </section>


  


</aside>



        
        
          <!--此文件用来存放一些不方便取值的变量-->
<!--思路大概是将值藏到重加载的区域内-->

<script>
  window.pdata={}
  pdata.ispage=false;
  pdata.postTitle="";
  pdata.commentPath="";
  pdata.commentPlaceholder="";

  var l_header=document.getElementById("l_header");
  
  l_header.classList.remove("show");
  
</script>

        
      </div>
      
  
  <footer class="footer clearfix">
    <br><br>
    
      
        <div class="aplayer-container">
          

  
    <meting-js
      theme='#1BCDFC'
      autoplay='true'
      volume='0.3'
      loop='all'
      order='random'
      fixed='false'
      list-max-height='320px'
      server='tencent'
      type='search'
      id='Mozart Lang Lang'
      list-folded='true'>
    </meting-js>
  


        </div>
      
    
      
        <br>
        <div class="social-wrapper">
          
            
              <a href="mailto:weikunhan@gmail.com"
                class="social fas fa-envelope-square flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
                
              </a>
            
          
            
              <a href="https://www.zhihu.com/people/weikunhan"
                class="social fas fa-pen-square flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
                
              </a>
            
          
            
              <a href="https://github.com/weikunhan/"
                class="social fab fa-github-square flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
                
              </a>
            
          
            
              <a href="https://www.linkedin.com/in/weikunhan/"
                class="social fab fa-linkedin flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
                
              </a>
            
          
            
              <a href="https://medium.com/@weikunhan300"
                class="social fab fa-medium flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
                
              </a>
            
          
            
              <a href="https://scholar.google.com/citations?user=MOfRj_YAAAAJ&amp;hl=en/"
                class="social fas fa-id-card flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
                
              </a>
            
          
            
              <a href="https://cdn.jsdelivr.net/gh/weikunhan/cdn-documents@latest/resumes/curriculum_vitae_1.pdf"
                class="social fas fa-file-download flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
                
              </a>
            
          
        </div>
      
    
      
        Use
        <a href="https://github.com/volantis-x/hexo-theme-volantis/tree/4.1.1" target="_blank" class="codename">Volantis</a>
        as theme
      
    
      
        
          <div><p><span id="lc-sv">Total visits <span id='number'><i class="fas fa-circle-notch fa-spin fa-fw" aria-hidden="true"></i></span> times</span></p>
</div>
        
      
    
      
        <div class='copyright'>
        <p>Copyright © 2020 Weikun Han</p>

        </div>
      
    
  </footer>


      <a id="s-top" class="fas fa-arrow-up fa-fw" href='javascript:void(0)'></a>
    </div>
  </div>
  <div>
    <script>
window.volantis={};
/********************脚本懒加载函数********************************/
function loadScript(src, cb) {
var HEAD = document.getElementsByTagName('head')[0] || document.documentElement;
var script = document.createElement('script');
script.setAttribute('type','text/javascript');
if (cb) script.onload = cb;
script.setAttribute('src', src);
HEAD.appendChild(script);
}
//https://github.com/filamentgroup/loadCSS
var loadCSS = function( href, before, media, attributes ){
	var doc = window.document;
	var ss = doc.createElement( "link" );
	var ref;
	if( before ){
		ref = before;
	}
	else {
		var refs = ( doc.body || doc.getElementsByTagName( "head" )[ 0 ] ).childNodes;
		ref = refs[ refs.length - 1];
	}
	var sheets = doc.styleSheets;
	if( attributes ){
		for( var attributeName in attributes ){
			if( attributes.hasOwnProperty( attributeName ) ){
				ss.setAttribute( attributeName, attributes[attributeName] );
			}
		}
	}
	ss.rel = "stylesheet";
	ss.href = href;
	ss.media = "only x";
	function ready( cb ){
		if( doc.body ){
			return cb();
		}
		setTimeout(function(){
			ready( cb );
		});
	}
	ready( function(){
		ref.parentNode.insertBefore( ss, ( before ? ref : ref.nextSibling ) );
	});
	var onloadcssdefined = function( cb ){
		var resolvedHref = ss.href;
		var i = sheets.length;
		while( i-- ){
			if( sheets[ i ].href === resolvedHref ){
				return cb();
			}
		}
		setTimeout(function() {
			onloadcssdefined( cb );
		});
	};
	function loadCB(){
		if( ss.addEventListener ){
			ss.removeEventListener( "load", loadCB );
		}
		ss.media = media || "all";
	}
	if( ss.addEventListener ){
		ss.addEventListener( "load", loadCB);
	}
	ss.onloadcssdefined = onloadcssdefined;
	onloadcssdefined( loadCB );
	return ss;
};
</script>
<!-- required -->

<script src="https://cdn.jsdelivr.net/npm/jquery@3.5/dist/jquery.min.js"></script>

<script>
  function pjax_fancybox() {
    $(".md .gallery").find("img").each(function () { //渲染 fancybox
      var element = document.createElement("a"); // a 标签
      $(element).attr("class", "fancybox");
      $(element).attr("pjax-fancybox", "");  // 过滤 pjax
      $(element).attr("href", $(this).attr("src"));
      if ($(this).attr("data-original")) {
        $(element).attr("href", $(this).attr("data-original"));
      }
      $(element).attr("data-fancybox", "images");
      var caption = "";   // 描述信息
      if ($(this).attr('alt')) {  // 判断当前页面是否存在描述信息
        $(element).attr('data-caption', $(this).attr('alt'));
        caption = $(this).attr('alt');
      }
      var div = document.createElement("div");
      $(div).addClass("fancybox");
      $(this).wrap(div); // 最外层套 div ，其实主要作用还是 class 样式
      var span = document.createElement("span");
      $(span).addClass("image-caption");
      $(span).text(caption); // 加描述
      $(this).after(span);  // 再套一层描述
      $(this).wrap(element);  // 最后套 a 标签
    })
    $(".md .gallery").find("img").fancybox({
      selector: '[data-fancybox="images"]',
      hash: false,
      loop: false,
      closeClick: true,
      helpers: {
        overlay: {closeClick: true}
      },
      buttons: [
        "zoom",
        "close"
      ]
    });
  };
  function SCload_fancybox() {
    if ($(".md .gallery").find("img").length == 0) return;
    loadCSS("https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css", document.getElementById("loadcss"));
    setTimeout(function() {
      loadScript('https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js', pjax_fancybox)
    }, 1);
  };
  $(function () {
    SCload_fancybox();
  });
</script>


<!-- internal -->

  
  
  
    
<script src="https://cdn.jsdelivr.net/npm/jquery-backstretch@2.1.18/jquery.backstretch.min.js"></script>

    <script type="text/javascript">
        var imgs=["https://cdn.jsdelivr.net/gh/weikunhan/cdn-documents@latest/wallpapers/abstract_A1.jpeg", "https://cdn.jsdelivr.net/gh/weikunhan/cdn-documents@latest/wallpapers/abstract_A2.jpeg", "https://cdn.jsdelivr.net/gh/weikunhan/cdn-documents@latest/wallpapers/abstract_B1.jpeg", "https://cdn.jsdelivr.net/gh/weikunhan/cdn-documents@latest/wallpapers/abstract_C1.jpeg", "https://cdn.jsdelivr.net/gh/weikunhan/cdn-documents@latest/wallpapers/abstract_D1.jpeg", "https://cdn.jsdelivr.net/gh/weikunhan/cdn-documents@latest/wallpapers/abstract_D2.jpeg"];
        if ('true' == 'true') {
          function shuffle(arr){
            /*From countercurrent-time*/
            var n = arr.length;
            while(n--) {
              var index = Math.floor(Math.random() * n);
              var temp = arr[index];
              arr[index] = arr[n];
              arr[n] = temp;
            }
          }
          shuffle(imgs);
        }
	  function Pjax_backstretch(){
        
          $('#cover-backstretch').backstretch(
            imgs,
          {
            duration: "30000",
            fade: "1500"
          });
        
	  }
	  loadScript("https://cdn.jsdelivr.net/npm/jquery-backstretch@2.1.18/jquery.backstretch.min.js",Pjax_backstretch)
    </script>
  







  <script defer src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.1.0/dist/lazyload.min.js"></script>
<script>
  // https://www.npmjs.com/package/vanilla-lazyload
  // Set the options globally
  // to make LazyLoad self-initialize
  window.lazyLoadOptions = {
    elements_selector: ".lazyload",
    threshold: 0
  };
  // Listen to the initialization event
  // and get the instance of LazyLoad
  window.addEventListener(
    "LazyLoad::Initialized",
    function (event) {
      window.lazyLoadInstance = event.detail.instance;
    },
    false
  );
  document.addEventListener('DOMContentLoaded', function () {
    lazyLoadInstance.update();
  });
  document.addEventListener('pjax:complete', function () {
    lazyLoadInstance.update();
  });
</script>




  
  
    <script>
      window.FPConfig = {
        delay: 0,
        ignoreKeywords: [],
        maxRPS: 5,
        hoverDelay: 25
      };
    </script>
    <script defer src="https://cdn.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"></script>
  








  <script>
  let APlayerController = new Object();
  APlayerController.id = 'Mozart Lang Lang';  // 设定全局音乐播放ID
  APlayerController.volume = '0.3';
</script>

  
<script src="https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.js"></script>


  
<script src="https://cdn.jsdelivr.net/npm/meting@2.0/dist/Meting.min.js"></script>








  
  
<script src="/js/valine.js"></script>


<script>
  var GUEST_INFO = ['nick', 'mail', 'link'];
  var meta = 'nick,mail,link'.split(',').filter(function (item) {
    return GUEST_INFO.indexOf(item) > -1
  });
  var REQUIRED_FIELDS = ['nick', 'mail', 'link'];
  var requiredFields = 'nick,mail'.split(',').filter(function (item) {
    return REQUIRED_FIELDS.indexOf(item) > -1
  });

  function emoji(path, idx, ext) {
    return path + "/" + path + "-" + idx + "." + ext;
  }

  var emojiMaps = {};
  for (var i = 1; i <= 54; i++) {
    emojiMaps['tieba-' + i] = emoji('tieba', i, 'png');
  }
  for (var i = 1; i <= 101; i++) {
    emojiMaps['qq-' + i] = emoji('qq', i, 'gif');
  }
  for (var i = 1; i <= 116; i++) {
    emojiMaps['aru-' + i] = emoji('aru', i, 'gif');
  }
  for (var i = 1; i <= 125; i++) {
    emojiMaps['twemoji-' + i] = emoji('twemoji', i, 'png');
  }
  for (var i = 1; i <= 4; i++) {
    emojiMaps['weibo-' + i] = emoji('weibo', i, 'png');
  }

  function pjax_valine() {
    if(!document.querySelectorAll("#valine_container")[0])return;

    let pagePlaceholder = pdata.commentPlaceholder || "快来评论吧~";

    let path = pdata.commentPath;
    if (path.length == 0) {
      let defaultPath = '';
      path = defaultPath || decodeURI(window.location.pathname);
    }

    var valine = new Valine();
    valine.init({
      el: '#valine_container',
      meta: meta,
      placeholder: pagePlaceholder,
      path: path,
      appId: "",
      appKey: "",
      pageSize: '10',
      avatar: 'robohash',
      lang: 'zh-cn',
      visitor: 'true',
      highlight: 'true',
      mathJax: 'false',
      enableQQ: 'true',
      recordIP: 'false',
      requiredFields: requiredFields,
      emojiCDN: 'https://cdn.jsdelivr.net/gh/volantis-x/cdn-emoji/valine/',
      emojiMaps: emojiMaps
    })
  }

  $(function () {
    pjax_valine();
  });
</script>





  
<script src="/js/app.js"></script>




  
    
<script src="/js/search.js"></script>

  


<!-- optional -->

  <script>
const SearchServiceimagePath="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@master/img/";
const ROOT =  ("/" || "/").endsWith('/') ? ("/" || "/") : ("//" || "/" );
(function ($) {
  
    customSearch = new HexoSearch({
      imagePath: SearchServiceimagePath
    });
  
})(jQuery);

</script>











  <script defer>

  const LCCounter = {
    app_id: 'u9j57bwJod4EDmXWdxrwuqQT-MdYXbMMI',
    app_key: 'jfHtEKVE24j0IVCGHbvuFClp',
    custom_api_server: '',

    // 查询存储的记录
    getRecord(Counter, url, title) {
      return new Promise(function (resolve, reject) {
        Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({url})))
          .then(resp => resp.json())
          .then(({results, code, error}) => {
            if (code === 401) {
              throw error;
            }
            if (results && results.length > 0) {
              var record = results[0];
              resolve(record);
            } else {
              Counter('post', '/classes/Counter', {url, title: title, times: 0})
                .then(resp => resp.json())
                .then((record, error) => {
                  if (error) {
                    throw error;
                  }
                  resolve(record);
                }).catch(error => {
                console.error('Failed to create', error);
                reject(error);
              });
            }
          }).catch((error) => {
          console.error('LeanCloud Counter Error:', error);
          reject(error);
        });
      })
    },

    // 发起自增请求
    increment(Counter, incrArr) {
      return new Promise(function (resolve, reject) {
        Counter('post', '/batch', {
          "requests": incrArr
        }).then((res) => {
          res = res.json();
          if (res.error) {
            throw res.error;
          }
          resolve(res);
        }).catch((error) => {
          console.error('Failed to save visitor count', error);
          reject(error);
        });
      });
    },

    // 构建自增请求体
    buildIncrement(objectId) {
      return {
        "method": "PUT",
        "path": `/1.1/classes/Counter/${ objectId }`,
        "body": {
          "times": {
            '__op': 'Increment',
            'amount': 1
          }
        }
      }
    },

    // 校验是否为有效的 UV
    validUV() {
      var key = 'LeanCloudUVTimestamp';
      var flag = localStorage.getItem(key);
      if (flag) {
        // 距离标记小于 24 小时则不计为 UV
        if (new Date().getTime() - parseInt(flag) <= 86400000) {
          return false;
        }
      }
      localStorage.setItem(key, new Date().getTime().toString());
      return true;
    },

    addCount(Counter) {
      var enableIncr = '' === 'true' && window.location.hostname !== 'localhost';
      enableIncr = true;
      var getterArr = [];
      var incrArr = [];
      // 请求 PV 并自增
      var pvCtn = document.querySelector('#lc-sv');
      if (pvCtn || enableIncr) {
        var pvGetter = this.getRecord(Counter, 'https://weikunhan.github.io' + '/#lc-sv', 'Visits').then((record) => {
          incrArr.push(this.buildIncrement(record.objectId))
          var eles = document.querySelectorAll('#lc-sv #number');
          if (eles.length > 0) {
            eles.forEach((el,index,array)=>{
              el.innerText = record.times + 1;
              if (pvCtn) {
                pvCtn.style.display = 'inline';
              }
            })
          }
        });
        getterArr.push(pvGetter);
      }

      // 请求 UV 并自增
      var uvCtn = document.querySelector('#lc-uv');
      if (uvCtn || enableIncr) {
        var uvGetter = this.getRecord(Counter, 'https://weikunhan.github.io' + '/#lc-uv', 'Visitors').then((record) => {
          var vuv = this.validUV();
          vuv && incrArr.push(this.buildIncrement(record.objectId))
          var eles = document.querySelectorAll('#lc-uv #number');
          if (eles.length > 0) {
            eles.forEach((el,index,array)=>{
              el.innerText = record.times + (vuv ? 1 : 0);
              if (uvCtn) {
                uvCtn.style.display = 'inline';
              }
            })
          }
        });
        getterArr.push(uvGetter);
      }

      // 请求文章的浏览数，如果是当前页面就自增
      var allPV = document.querySelectorAll('#lc-pv');
      if (allPV.length > 0 || enableIncr) {
        for (i = 0; i < allPV.length; i++) {
          let pv = allPV[i];
          let title = pv.getAttribute('data-title');
          var url = 'https://weikunhan.github.io' + pv.getAttribute('data-path');
          if (url) {
            var viewGetter = this.getRecord(Counter, url, title).then((record) => {
              // 是当前页面就自增
              let curPath = window.location.pathname;
              if (curPath.includes('index.html')) {
                curPath = curPath.substring(0, curPath.lastIndexOf('index.html'));
              }
              if (pv.getAttribute('data-path') == curPath) {
                incrArr.push(this.buildIncrement(record.objectId));
              }
              if (pv) {
                var ele = pv.querySelector('#lc-pv #number');
                if (ele) {
                  if (pv.getAttribute('data-path') == curPath) {
                    ele.innerText = (record.times || 0) + 1;
                  } else {
                    ele.innerText = record.times || 0;
                  }
                  pv.style.display = 'inline';
                }
              }
            });
            getterArr.push(viewGetter);
          }
        }
      }

      // 如果启动计数自增，批量发起自增请求
      if (enableIncr) {
        Promise.all(getterArr).then(() => {
          incrArr.length > 0 && this.increment(Counter, incrArr);
        })
      }

    },


    fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${ api_server }/1.1${ url }`, {
          method,
          headers: {
            'X-LC-Id': this.app_id,
            'X-LC-Key': this.app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      this.addCount(Counter);
    },

    refreshCounter() {
      var api_server = this.app_id.slice(-9) !== '-MdYXbMMI' ? this.custom_api_server : `https://${ this.app_id.slice(0, 8).toLowerCase() }.api.lncldglobal.com`;
      if (api_server) {
        this.fetchData(api_server);
      } else {
        fetch('https://app-router.leancloud.cn/2/route?appId=' + this.app_id)
          .then(resp => resp.json())
          .then(({api_server}) => {
            this.fetchData('https://' + api_server);
          });
      }
    }

  };

  LCCounter.refreshCounter();

  document.addEventListener('pjax:complete', function () {
    LCCounter.refreshCounter();
  });
</script>




  <script>
const rootElement = document.documentElement;
const darkModeStorageKey = "user-color-scheme";
const rootElementDarkModeAttributeName = "data-user-color-scheme";

const setLS = (k, v) => {
  try {
    localStorage.setItem(k, v);
  } catch (e) {
    console.log(e.message);
  }
};

const removeLS = (k) => {
  try {
    localStorage.removeItem(k);
  } catch (e) {
    console.log(e.message);
  }
};

const getLS = (k) => {
  try {
    return localStorage.getItem(k);
  } catch (e) {
    console.log(e.message);
    return null;
  }
};

const getModeFromCSSMediaQuery = () => {
  return window.matchMedia("(prefers-color-scheme: dark)").matches
    ? "dark"
    : "light";
};

const resetRootDarkModeAttributeAndLS = () => {
  rootElement.removeAttribute(rootElementDarkModeAttributeName);
  removeLS(darkModeStorageKey);
};

const validColorModeKeys = {
  dark: true,
  light: true,
};

const applyCustomDarkModeSettings = (mode) => {
  const currentSetting = mode || getLS(darkModeStorageKey);

  if (currentSetting === getModeFromCSSMediaQuery()) {
    resetRootDarkModeAttributeAndLS();
  } else if (validColorModeKeys[currentSetting]) {
    rootElement.setAttribute(rootElementDarkModeAttributeName, currentSetting);
  } else {
    resetRootDarkModeAttributeAndLS();
  }
};

const invertDarkModeObj = {
  dark: "light",
  light: "dark",
};

/**
 * get target mode
 */
const toggleCustomDarkMode = () => {
  let currentSetting = getLS(darkModeStorageKey);

  if (validColorModeKeys[currentSetting]) {
    currentSetting = invertDarkModeObj[currentSetting];
  } else if (currentSetting === null) {
    currentSetting = invertDarkModeObj[getModeFromCSSMediaQuery()];
  } else {
    return;
  }
  setLS(darkModeStorageKey, currentSetting);
  return currentSetting;
};

/**
 * bind click event for toggle button
 */
function bindToggleButton() {
	var btn=$("#wrapper .toggle-mode-btn");
    btn.on('click',(e) => {
      const mode = toggleCustomDarkMode();
      applyCustomDarkModeSettings(mode);
    });
}
$("#wrapper .darkbtn").parents(".header").addClass("toggle-mode-btn")
applyCustomDarkModeSettings();
document.addEventListener("DOMContentLoaded", bindToggleButton);
document.addEventListener("pjax:success", bindToggleButton);
var now = new Date();
var hour = now.getHours();
if (hour < 7 && hour >= 19) {
	var mode = toggleCustomDarkMode();
	if (mode === "dark") {
	  applyCustomDarkModeSettings(mode);
	}
}
</script>






<script>
function listennSidebarTOC() {
  const navItems = document.querySelectorAll(".toc li");
  if (!navItems.length) return;
  const sections = [...navItems].map((element) => {
    const link = element.querySelector(".toc-link");
    const target = document.getElementById(
      decodeURI(link.getAttribute("href")).replace("#", "")
    );
    link.addEventListener("click", (event) => {
      event.preventDefault();
      window.scrollTo({
		top: target.offsetTop + 100,
		
		behavior: "smooth"
		
	  });
    });
    return target;
  });

  function activateNavByIndex(target) {
    if (target.classList.contains("active-current")) return;

    document.querySelectorAll(".toc .active").forEach((element) => {
      element.classList.remove("active", "active-current");
    });
    target.classList.add("active", "active-current");
    let parent = target.parentNode;
    while (!parent.matches(".toc")) {
      if (parent.matches("li")) parent.classList.add("active");
      parent = parent.parentNode;
    }
  }

  function findIndex(entries) {
    let index = 0;
    let entry = entries[index];
    if (entry.boundingClientRect.top > 0) {
      index = sections.indexOf(entry.target);
      return index === 0 ? 0 : index - 1;
    }
    for (; index < entries.length; index++) {
      if (entries[index].boundingClientRect.top <= 0) {
        entry = entries[index];
      } else {
        return sections.indexOf(entry.target);
      }
    }
    return sections.indexOf(entry.target);
  }

  function createIntersectionObserver(marginTop) {
    marginTop = Math.floor(marginTop + 10000);
    let intersectionObserver = new IntersectionObserver(
      (entries, observe) => {
        let scrollHeight = document.documentElement.scrollHeight + 100;
        if (scrollHeight > marginTop) {
          observe.disconnect();
          createIntersectionObserver(scrollHeight);
          return;
        }
        let index = findIndex(entries);
        activateNavByIndex(navItems[index]);
      },
      {
        rootMargin: marginTop + "px 0px -100% 0px",
        threshold: 0,
      }
    );
    sections.forEach((element) => {
      element && intersectionObserver.observe(element);
    });
  }
  createIntersectionObserver(document.documentElement.scrollHeight);
}

document.addEventListener("DOMContentLoaded", listennSidebarTOC);
document.addEventListener("pjax:success", listennSidebarTOC);
</script>

<!-- more -->




    
      


<script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script>

<!-- 样式位于：source/css/_third-party/pjaxanimate.styl -->

<div class="pjax-animate">
  
    <script src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script>
    <div id="loading-bar-wrapper"><script>NProgress.configure({parent:"#loading-bar-wrapper",trickleSpeed: 100})</script></div>
    <script>
      window.ShowLoading = function() {
        NProgress.start();
      };
      window.HideLoading = function() {
        NProgress.done();
      }
    </script>
  
</div>

<script>
    var pjax;
    document.addEventListener('DOMContentLoaded', function () {
      pjax = new Pjax({
        elements: 'a[href]:not([href^="#"]):not([href="javascript:void(0)"]):not([pjax-fancybox])',
        selectors: [
          "title",
          "#l_cover",
          "#pjax-container",
          "#pjax-header-nav-list"
        ],
        cacheBust: false,   // url 地址追加时间戳，用以避免浏览器缓存
        timeout: 5000
      });
    });

    document.addEventListener('pjax:send', function (e) {
      //window.stop(); // 相当于点击了浏览器的停止按钮

      try {
        var currentUrl = window.location.pathname;
        var targetUrl = e.triggerElement.href;
        var banUrl = [""];
        if (banUrl[0] != "") {
          banUrl.forEach(item => {
            if(currentUrl.indexOf(item) != -1 || targetUrl.indexOf(item) != -1) {
              window.location.href = targetUrl;
            }
          });
        }
      } catch (error) {}

      window.subData = null; // 移除标题（用于一二级导航栏切换处）
      if (typeof $.fancybox != "undefined") {
        $.fancybox.close();    // 关闭弹窗
      }
      volantis.$switcher.removeClass('active'); // 关闭移动端激活的搜索框
      volantis.$header.removeClass('z_search-open'); // 关闭移动端激活的搜索框
      volantis.$wrapper.removeClass('sub'); // 跳转页面时关闭二级导航

      // 解绑事件 避免重复监听
      volantis.$topBtn.unbind('click');
      $('.menu a').unbind('click');
      $(window).unbind('resize');
      $(window).unbind('scroll');
      $(document).unbind('scroll');
      $(document).unbind('click');
      $('body').unbind('click');
      window.ShowLoading();
    });

    document.addEventListener('pjax:complete', function () {
      // 关于百度统计对 SPA 页面的处理：
      // 方案一：百度统计>管理>单页应用设置中，打开开启按钮即可对SPA进行统计。 https://tongji.baidu.com/web/help/article?id=324
      // 方案二：取消注释下列代码。 https://tongji.baidu.com/web/help/article?id=235
      // 

      // 关于谷歌统计对 SPA 页面的处理：
      // 当应用以动态方式加载内容并更新地址栏中的网址时，也应该更新通过 gtag.js 存储的网页网址。
      // https://developers.google.cn/analytics/devguides/collection/gtagjs/single-page-applications?hl=zh-cn
      

      $('.nav-main').find('.list-v').not('.menu-phone').removeAttr("style",""); // 移除小尾巴的移除
      $('.menu-phone.list-v').removeAttr("style",""); // 移除小尾巴的移除
      $('script[data-pjax], .pjax-reload script').each(function () {
        $(this).parent().append($(this).remove());
      });
      try{
          if (typeof $.fancybox == "undefined") {
            SCload_fancybox();
          } else {
            pjax_fancybox();
          }
        
		  Pjax_backstretch()
        
        
        
        
        
        
          pjax_valine();
        
        
        
        
      } catch (e) {
        console.log(e);
      }
      window.HideLoading();
    });

    document.addEventListener('pjax:error', function (e) {
      window.HideLoading();
      window.location.href = e.triggerElement.href;
    });
</script>

    
  </div>
</body>
</html>
